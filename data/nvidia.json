[
   {
      "name": "unit",
      "clock": "GHz",
      "fp64": "TFLOPS",
      "fp32": "TFLOPS",
      "fp16": "TFLOPS",
      "bf16": "TFLOPS",
      "fp64-tensor core": "TFLOPS",
      "fp32-tensor core": "TFLOPS",
      "fp16-tensor core": "TFLOPS",
      "bf16-tensor core": "TFLOPS",
      "int8-tensor core": "TFLOPS",
      "fp8-tensor core": "TFLOPS",
      "fp6-tensor core": "TFLOPS",
      "fp4-tensor core": "TFLOPS",
      "fp32-tensor core-sparse": "TFLOPS",
      "fp16-tensor core-sparse": "TFLOPS",
      "bf16-tensor core-sparse": "TFLOPS",
      "int8-tensor core-sparse": "TFLOPS",
      "fp8-tensor core-sparse": "TFLOPS",
      "fp6-tensor core-sparse": "TFLOPS",
      "fp4-tensor core-sparse": "TFLOPS",
      "icache": "KB",
      "register size": "KB",
      "l1-memory size": "MB",
      "l1-bandwidth": "TB/s",
      "l1-latency": "cycles",
      "l2-memory size": "MB",
      "l2-bandwidth": "TB/s",
      "l2-latency": "cycles",
      "l3-memory size": "GB",
      "l3-memory-bus-width": "bits",
      "l3-bandwidth": "TB/s",
      "l3-latency": "cycles",
      "die size": "mm²",
      "tdp": "W"
   },
   {
      "name": "H100 SXM",
      "architecture": "Hopper",
      "clock": 1.98,
      "fp64": 34,
      "fp32": 67,
      "fp16": 133.82,
      "bf16": 133.82,
      "fp64-tensor core": 34,
      "fp32-tensor core": 67,
      "fp16-tensor core": 989.50,
      "bf16-tensor core": 989.50,
      "int8-tensor core": 1979.00,
      "fp8-tensor core": null,
      "fp6-tensor core": null,
      "fp4-tensor core": null,
      "fp32-tensor core-sparse": null,
      "fp16-tensor core-sparse": 1917,
      "bf16-tensor core-sparse": 4530,
      "int8-tensor core-sparse": 9060,
      "fp8-tensor core-sparse": 9060,
      "fp6-tensor core-sparse": null,
      "fp4-tensor core-sparse": null,
      "icache": 6336.00,
      "register size": 33792.00,
      "l1-memory size": 49.50,
      "l1-bandwidth": 30.43,
      "l1-latency": null,
      "l1-port": null,
      "l2-memory size": null,
      "l2-bandwidth": null,
      "l2-latency": null,
      "l2-port": null,
      "l3-memory size": 80,
      "l3-memory-architecture": "HBM3",
      "l3-memory-bus-width": 5120,
      "l3-bandwidth": 3430.40,
      "l3-latency": null,
      "l3-port": null,
      "has-decompression engine": true,
      "cpu-core": null,
      "cpu-architecture": null,
      "die size": 814,
      "tdp": 700,
      "release date": "2022",
      "manufacturing process": "TSMC 4N",
      "sources": [
         "https://www.nvidia.com/en-us/data-center/h100/",
         "https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/h100/h100-datasheet-update-nvidia-1454981-r5-web.pdf"
      ]
   },
   {
      "name": "B100",
      "architecture": "Blackwell",
      "clock": null,
      "fp64": null,
      "fp32": null,
      "fp16": 0,
      "bf16": 0,
      "fp64-tensor core": 30,
      "fp32-tensor core": null,
      "fp16-tensor core": 1800,
      "bf16-tensor core": 1800,
      "int8-tensor core": 3500,
      "fp8-tensor core": 3500,
      "fp6-tensor core": 3500,
      "fp4-tensor core": 7000,
      "fp32-tensor core-sparse": null,
      "fp16-tensor core-sparse": 3500,
      "bf16-tensor core-sparse": 3500,
      "int8-tensor core-sparse": 7000,
      "fp8-tensor core-sparse": 7000,
      "fp6-tensor core-sparse": 7000,
      "fp4-tensor core-sparse": 14000,
      "icache": null,
      "register size": null,
      "l1-memory size": null,
      "l1-bandwidth": null,
      "l1-latency": null,
      "l1-port": null,
      "l2-memory size": null,
      "l2-bandwidth": null,
      "l2-latency": null,
      "l2-port": null,
      "l3-memory size": 192,
      "l3-memory-architecture": null,
      "l3-memory-bus-width": 8192,
      "l3-bandwidth": 8000,
      "l3-latency": null,
      "l3-port": null,
      "has-decompression engine": null,
      "cpu-core": null,
      "cpu-architecture": null,
      "die size": null,
      "tdp": 700,
      "release date": null,
      "manufacturing process": "TSMC 4NP",
      "sources": [
         "https://www.anandtech.com/show/21310/nvidia-blackwell-architecture-and-b200b100-accelerators-announced-going-bigger-with-smaller-data"
      ]
   },
   {
      "name": "GB200",
      "architecture": "Blackwell",
      "clock": null,
      "fp64": 90,
      "fp32": 180,
      "fp16": 0,
      "bf16": 0,
      "fp64-tensor core": 90,
      "fp32-tensor core": 2500,
      "fp16-tensor core": 5000,
      "bf16-tensor core": 5000,
      "int8-tensor core": 10000,
      "fp8-tensor core": 10000,
      "fp6-tensor core": 10000,
      "fp4-tensor core": 20000,
      "fp32-tensor core-sparse": 5000,
      "fp16-tensor core-sparse": 10000,
      "bf16-tensor core-sparse": 10000,
      "int8-tensor core-sparse": 20000,
      "fp8-tensor core-sparse": 20000,
      "fp6-tensor core-sparse": 20000,
      "fp4-tensor core-sparse": 40000,
      "icache": null,
      "register size": null,
      "l1-memory size": null,
      "l1-bandwidth": null,
      "l1-latency": null,
      "l1-port": null,
      "l2-memory size": null,
      "l2-bandwidth": null,
      "l2-latency": null,
      "l2-port": null,
      "l3-memory size": 384,
      "l3-memory-architecture": "HBM3e 8x2-sites",
      "l3-memory-bus-width": 16384,
      "l3-bandwidth": 16000,
      "l3-latency": null,
      "l3-port": null,
      "has-decompression engine": true,
      "cpu-core": 72,
      "cpu-architecture": "Arm® Neoverse V2 cores",
      "die size": null,
      "tdp": 2700,
      "release date": "2025-03-18",
      "manufacturing process": "TSMC 4NP",
      "sources": [
         "https://resources.nvidia.com/en-us-blackwell-architecture",
         "https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing"
      ]
   },
   {
      "name": "DGX B300",
      "architecture": "Blackwell",
      "clock": null,
      "fp64": null,
      "fp32": null,
      "fp16": null,
      "bf16": null,
      "fp64-tensor core": null,
      "fp32-tensor core": null,
      "fp16-tensor core": null,
      "bf16-tensor core": null,
      "int8-tensor core": null,
      "fp8-tensor core": null,
      "fp6-tensor core": null,
      "fp4-tensor core": null,
      "fp32-tensor core-sparse": null,
      "fp16-tensor core-sparse": null,
      "bf16-tensor core-sparse": null,
      "int8-tensor core-sparse": null,
      "fp8-tensor core-sparse": 72000,
      "fp6-tensor core-sparse": null,
      "fp4-tensor core-sparse": 144000,
      "icache": null,
      "register size": null,
      "l1-memory size": null,
      "l1-bandwidth": null,
      "l1-latency": null,
      "l1-port": null,
      "l2-memory size": null,
      "l2-bandwidth": null,
      "l2-latency": null,
      "l2-port": null,
      "l3-memory size": 2300,
      "l3-memory-architecture": null,
      "l3-memory-bus-width": 14400,
      "l3-bandwidth": null,
      "l3-latency": null,
      "l3-port": null,
      "has-decompression engine": null,
      "cpu-core": null,
      "cpu-architecture": "Dual Intel® Xeon® Processors",
      "die size": null,
      "tdp": 14000,
      "release date": "2025-03-19",
      "manufacturing process": "TSMC 4NP",
      "sources": [
         "https://resources.nvidia.com/en-us-blackwell-architecture",
         "https://www.nvidia.com/en-us/data-center/dgx-b300/",
         "https://resources.nvidia.com/en-us-dgx-systems/dgx-b300-datasheet?ncid=no-ncid"
      ]
   }
]